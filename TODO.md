# TODO: Lists for Preliminary Study

## Small tasks
> week7: 04/04 - 08/04
- [x] Learned how DDPG works (read, write, implement)
- [ ] Learned how TD3 works (read, write, implement)
- [ ] Learned how SAC works (read, write, implement)
- [x] Find what is a solution in pyribs
- [x] Run a couple of basic scenarios on Lunar Lander

> week8: 11/04 - 15/04
- [x] Make a Gantt Chart
- [x] Read the QD paper on CMAP-Elites
- [x] Check 'colas2020scaling' which uses QD for fault-tolerant robot control.
- [x] Adapt PD-ERL for LunarLander (continuous)
- [ ] Test QD learned polices on damaged lunar lander. It is very interesting to see how well they perform before any online learning.
- [ ] Find out what the batch_size is in QD

> week9: 16/04 - 22/04
- [] Make table for overview of ERL, DRL and QD.
- [] Find out how to make a NN policy in pyribs
    - [] Implement a NN policy in pyribs on LuanrLander

<!-- % \item Code a simple combination between QD and a ERL framework (most probably PD-ERL) -->
## Report Writing:
- [x] Novelty search and QD intro
- [ ] Prepare nice diagram
- [ ] Background on FT
- [ ] Background on RL
- [ ] SOTA DRL
- 

# Ideas
 - Test fewer envs. and papers for the lit study
 - 



# Things to check later
- still not sure how actor-critic frameworks should be implemented
- Try MPI from OpenAI https://spinningup.openai.com/en/latest/utils/mpi.html

