# TODO: Lists for Preliminary Study

## Invidual Tasks (per week)
> week 7: 04/04 - 08/04
- [x] Learned how DDPG works (read, write, implement)
- [x] Learned how TD3 works (read, write, implement)
- [x] Learned how SAC works (read, write, implement)
- [x] Find what is a solution in pyribs
- [x] Run a couple of basic scenarios on Lunar Lander

> week 8: 11/04 - 15/04
- [x] Make a Gantt Chart
- [x] Read the QD paper on CMAP-Elites
- [x] Check 'colas2020scaling' which uses QD for fault-tolerant robot control.
- [x] Adapt PD-ERL for LunarLander (continuous)
- [x] Test QD learned polices on damaged lunar lander. It is very interesting to see how well they perform before any online learning.
- [x] Find out what the batch_size is in QD

> week 9: 16/04 - 22/04
- [x] Make table for overview of ERL, DRL and QD.
- [x] <s> Find out how to make a NN policy in pyribs</s> - NOT REELVANT 
 

> week10: 02/05 - 06/05
- [x] Improve general fault-tolerant control diagram
- [x] Finish PD-ERL diagram
- [x] Finish writing about DL

> week 11: 09/05 - 14/05
- [x] Write about ERL: figure, pseudocode, results
- [x] Write the ERL sota:
    - [x] comparing table from the review paper
    - [x] explanations
    - [x] motivate decision
- [x] Make nice plotting functions
- [x] Wrap LunarLander in a global env


> week 12: 16/05 - 20/05
- [x] Test on LunarLander with faulty state measurement
- [x] Finish writing about PDERL: 
  - [x] figure
  - [x] tricks
  - [x] results


> week 13: 23/05 - 27/05
- [x] Rerun archive map on LunarLander Nominal
- [x] Explain the testing environment
- [x] Write DRL in flight Control

> week 14: 30/05 - 01/06
- [x] Fix the bug in the behavioral maps
- [x] Report writing:
  - [x] intro
  - [x] research questions
  - [x] conclusion
  - [x] future work
- [x] Proofreading 

> week 15: 07/06 -10/06
- [x] Prepare Gantt chart for the main thesis phase
- [x] Compile PH-lab model on Ubuntu
- [x] Clean github repo 


> week 16: 13/06 - 17/06
- [ ] Implement TD3 agent:
  - [x] dueling Q-networks
  - [x] delayed updates
  - [ ] target policy softening
  - [ ] test on lunarlander
- [ ] Add reward function to the PH-lab env
  
  
<!-- % \item Code a simple combination between QD and a ERL framework (most probably PD-ERL) -->
## Prepare Presentation:
- [ ] Schedule it
- [ ] Gather other presentations
- [ ] Motivation and aim
- [ ] Literature review
- [ ] Method
- [ ] Preliminary results


# Ideas



# Things to check later
- Try MPI from OpenAI https://spinningup.openai.com/en/latest/utils/mpi.html

