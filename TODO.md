# TODO: Lists for Preliminary Study

## Invidual Tasks (per week)
> week 7: 04/04 - 08/04
- [x] Learned how DDPG works (read, write, implement)
- [x] Learned how TD3 works (read, write, implement)
- [x] Learned how SAC works (read, write, implement)
- [x] Find what is a solution in pyribs
- [x] Run a couple of basic scenarios on Lunar Lander


> week 8: 11/04 - 15/04
- [x] Make a Gantt Chart
- [x] Read the QD paper on CMAP-Elites
- [x] Check 'colas2020scaling' which uses QD for fault-tolerant robot control.
- [x] Adapt PD-ERL for LunarLander (continuous)
- [x] Test QD learned polices on damaged lunar lander. It is very interesting to see how well they perform before any online learning.
- [x] Find out what the batch_size is in QD

> week 9: 16/04 - 22/04
- [x] Make table for overview of ERL, DRL and QD.
- [x] <s> Find out how to make a NN policy in pyribs</s> - NOT REELVANT 
 

> week10: 02/05 - 06/05
- [x] Improve general fault-tolerant control diagram
- [x] Finish PD-ERL diagram
- [x] Finish writing about DL

> week 11: 09/05 - 14/05
- [x] Write about ERL: figure, pseudocode, results
- [x] Write the ERL sota:
    - [x] comparing table from the review paper
    - [x] explanations
    - [x] motivate decision
- [x] Make nice plotting functions
- [x] Wrap LunarLander in a global env


> week 12: 16/05 - 20/05
- [x] Test on LunarLander with faulty state measurement
- [x] Finish writing about PDERL: 
  - [x] figure
  - [x] tricks
  - [x] results

> week 13: 23/05 - 27/05
- [x] Rerun archive map on LunarLander Nominal
- [x] Explain the testing environment
- [x] Write DRL in flight Control

> week 14: 30/05 - 01/06
- [x] Fix the bug in the behavioral maps
- [x] Report writing:
  - [x] intro
  - [x] research questions
  - [x] conclusion
  - [x] future work
- [x] Proofreading 

> week 15: 07/06 -10/06
- [x] Prepare Gantt chart for the main thesis phase
- [x] Compile PH-lab model on Ubuntu
- [x] Clean github repo 


> week 16: 13/06 - 17/06
- [x] Implement TD3 agent:
  - [x] dueling Q-networks
  - [x] delayed updates
  - [x] target policy softening
  - [x] test on lunarlander
- [x] Make PHlab to a gym-like envriornemnt
  

> week 17: 20/06 - 24/06
- [x] Implement Dask parallelisation
- [x] Add reward function

> week 18: 27/06 - 01/07
- [x] Presentation
- [x] Test on longitudinal control 
- [ ] Add episode bounds
<!-- % \item Code a simple combination between QD and a ERL framework (most probably PD-ERL) -->

> week 19: 04/07 - 08/07
- [x] PSimplify to TD3 on lon control
  - [ ] tune yd3 actors and critics
- [x] Test on longitudinal control 

> week 30: 11/07 - 15/07
- [ ] Run TD3-ERL on full attitude control for at least 500_000 frames
- [ ] Connect via SSH to the remote station
- [ ] Train TD3 on full attitude control 
- [ ] Implement new reward regularization

  

# Ideas



# Things to check later
- Try MPI from OpenAI https://spinningup.openai.com/en/latest/utils/mpi.html

